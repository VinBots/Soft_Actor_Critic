{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control -> SAC with entropy maximization\n",
    "# CRAWLER\n",
    "\n",
    "---\n",
    "\n",
    "This notebook implements the Soft Actor-Critic Algorithm as documented in the paper [here](https://arxiv.org/pdf/1812.05905.pdf)\n",
    "\n",
    "Useful references\n",
    "[berkeley repository](https://github.com/rail-berkeley/softlearning/blob/master/softlearning/algorithms/sac.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulation parameters\n",
    "train_mode = True #test mode if False\n",
    "load_mode=False #set it to True in test mode (train_mode = False)\n",
    "\n",
    "save_mode = False #save the networks - train_mode only\n",
    "\n",
    "#Task parameters\n",
    "\n",
    "state_dim = 129\n",
    "action_dim = 20\n",
    "solve_score = 2000.0\n",
    "\n",
    "# Key Hyperparameters for simulation-purpose\n",
    "\n",
    "auto_entropy_tuning = True\n",
    "init_temp = 0.1\n",
    "\n",
    "if auto_entropy_tuning==False:\n",
    "    alpha = 0.05\n",
    "\n",
    "single_q = False # this parameter is used to test the influence of the double Q minimization trick\n",
    "\n",
    "\n",
    "# Gemeral Hyperparameters\n",
    "layer_size=256\n",
    "weights_init_bound = 0.999\n",
    "replay_buffer_size=1000000\n",
    "num_epochs=10000\n",
    "num_steps_per_epoch=10000\n",
    "batch_size=layer_size\n",
    "discount=0.99\n",
    "soft_target_tau=0.005\n",
    "target_update_period=1\n",
    "\n",
    "policy_lr=0.0001\n",
    "qf_lr=policy_lr\n",
    "a_lr = policy_lr\n",
    "\n",
    "update_every = 1\n",
    "episods_before_learning = 0\n",
    "\n",
    "first_30 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import random\n",
    "import math\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: CrawlerBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 129\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 20\n",
      "        Vector Action descriptions: , , , , , , , , , , , , , , , , , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 12\n"
     ]
    }
   ],
   "source": [
    "# CPU / GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Launch the environment\n",
    "env = UnityEnvironment(file_name=\"Crawler.app\")\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "env_info = env.reset(train_mode=train_mode)[brain_name]      # reset the environment\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "#print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "#print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "#print('The state for the first agent looks like:', states[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftAgent(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, h1_size, h2_size, output_size):\n",
    "        super(SoftAgent, self).__init__()\n",
    "        \n",
    "        # state, hidden layer, action sizes\n",
    "        self.input_size = input_size\n",
    "        self.h1_size = h1_size\n",
    "        self.h2_size = h2_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # define layers\n",
    "        self.fc1 = nn.Linear(self.input_size, self.h1_size)\n",
    "        self.fc2 = nn.Linear(self.h1_size, self.h2_size)\n",
    "        self.fc3 = nn.Linear(self.h2_size, self.output_size)\n",
    "        \n",
    "        #initialize weights\n",
    "        init_w = 3e-3\n",
    "        self.fc3.weight.data.uniform_(-init_w,init_w)\n",
    "        self.fc3.bias.data.uniform_(-init_w,init_w)            \n",
    "        \n",
    "    def forward(self, state,action):\n",
    "        x = torch.cat([state,action],1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianPolicy(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, h1_size, h2_size, output_mean_size, output_std_size):\n",
    "        super(GaussianPolicy, self).__init__()\n",
    "        \n",
    "        # state, hidden layer, action sizes\n",
    "        self.input_size = input_size\n",
    "        self.h1_size = h1_size\n",
    "        self.h2_size = h2_size\n",
    "        self.output_mean_size = output_mean_size\n",
    "        self.output_std_size = output_std_size\n",
    "        # define layers\n",
    "        self.fc1 = nn.Linear(self.input_size, self.h1_size)\n",
    "        self.fc2 = nn.Linear(self.h1_size, self.h2_size)\n",
    "        self.fc3_mean = nn.Linear(self.h2_size, self.output_mean_size)\n",
    "        self.fc3_log_std = nn.Linear(self.h2_size, self.output_std_size)\n",
    "        #initialize weights\n",
    "        init_w = 3e-3\n",
    "        self.fc3_mean.weight.data.uniform_(-init_w,init_w)\n",
    "        self.fc3_mean.bias.data.uniform_(-init_w,init_w)\n",
    "        self.fc3_log_std.weight.data.uniform_(-init_w,init_w)\n",
    "        self.fc3_log_std.bias.data.uniform_(-init_w,init_w)\n",
    "                        \n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mean = self.fc3_mean(x) #values of the action should be between -1 and 1 so this is not the mean of the action value\n",
    "        log_std = self.fc3_log_std(x)\n",
    "        log_std_min = -20\n",
    "        log_std_max = 0\n",
    "        log_std = torch.clamp(log_std,log_std_min, log_std_max)              \n",
    "        return mean,log_std\n",
    "    \n",
    "    def sample (self,state,epsilon = 1e-6):\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()\n",
    "        normal = Normal (mean,std)\n",
    "        z = normal.rsample()\n",
    "        action = torch.tanh(z) \n",
    "        log_pi = normal.log_prob(z) - torch.log(1 - action.pow(2) + epsilon)\n",
    "        log_pi = log_pi.sum(1,keepdim=True)\n",
    "        return action, log_pi\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        std = log_std.exp()   \n",
    "        normal = Normal(mean, std)\n",
    "        z = normal.sample() #sample an action from a normal distribution with (mean,std)\n",
    "        action = torch.tanh(z) #squeeze the value between -1 and 1\n",
    "        action = action.cpu().detach().squeeze(0).numpy()\n",
    "        return self.rescale_action(action)\n",
    "    \n",
    "    def get_action2(self, state): #used for testing purpose - we remove the stochasticity of the sampling step\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        mean, log_std = self.forward(state)\n",
    "        action = torch.tanh(mean)\n",
    "        action = action.cpu().detach().squeeze(0).numpy()\n",
    "        return self.rescale_action(action)\n",
    "    \n",
    "    def rescale_action(self, action):\n",
    "        action_range=[-1,1]\n",
    "        return action * (action_range[1] - action_range[0]) / 2.0 +\\\n",
    "            (action_range[1] + action_range[0]) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        #dones = dones.view(dones.size(0), -1)\n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def buffer_len(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qf1 = SoftAgent(\n",
    "    input_size = state_dim + action_dim,\n",
    "    h1_size = layer_size,\n",
    "    h2_size = layer_size,\n",
    "    output_size=1\n",
    ").to(device)\n",
    "qf1_optimizer = optim.Adam(qf1.parameters(), lr=qf_lr)\n",
    "\n",
    "qf2 = SoftAgent(\n",
    "    input_size = state_dim + action_dim,\n",
    "    h1_size = layer_size,\n",
    "    h2_size = layer_size,\n",
    "    output_size=1\n",
    ").to(device)\n",
    "qf2_optimizer = optim.Adam(qf2.parameters(), lr=qf_lr)\n",
    "\n",
    "target_qf1 = SoftAgent(\n",
    "    input_size = state_dim + action_dim,\n",
    "    h1_size = layer_size,\n",
    "    h2_size = layer_size,\n",
    "    output_size=1\n",
    ").to(device)\n",
    "\n",
    "target_qf2 = SoftAgent(\n",
    "    input_size = state_dim + action_dim,\n",
    "    h1_size = layer_size,\n",
    "    h2_size = layer_size,\n",
    "    output_size=1\n",
    ").to(device)\n",
    "\n",
    "policy = GaussianPolicy(\n",
    "    input_size = state_dim,\n",
    "    h1_size = layer_size,\n",
    "    h2_size = layer_size,\n",
    "    output_mean_size = action_dim,\n",
    "    output_std_size = action_dim\n",
    ").to(device)\n",
    "policy_optimizer = optim.Adam(policy.parameters(), lr=policy_lr)\n",
    "\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size, batch_size, 1)\n",
    "\n",
    "if auto_entropy_tuning:    \n",
    "    target_entropy = -20 #torch.prod(torch.Tensor(20,1).to(device)).item()\n",
    "    log_alpha = torch.tensor(np.log(init_temp), requires_grad=True, device=device)\n",
    "    log_alpha_optim = optim.Adam([log_alpha], lr=a_lr)\n",
    "    alpha = log_alpha.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_mode:\n",
    "    qf1.load_state_dict(torch.load('checkpoint_qf1.pth'))\n",
    "    qf1.eval()\n",
    "    \n",
    "    qf2.load_state_dict(torch.load('checkpoint_qf2.pth'))\n",
    "    qf2.eval()\n",
    "    \n",
    "    policy.load_state_dict(torch.load('checkpoint_policy.pth'))\n",
    "    policy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy parameters of qf1 to target_qf1\n",
    "\n",
    "for target_params, params in zip(target_qf1.parameters(), qf1.parameters()):\n",
    "    target_params.data.copy_(params)\n",
    "\n",
    "for target_params, params in zip(target_qf2.parameters(), qf2.parameters()):\n",
    "    target_params.data.copy_(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    \n",
    "    global alpha\n",
    "    global log_alpha\n",
    "    global update_step\n",
    "    delay_step = 1\n",
    "    global soft_target_tau\n",
    "    \n",
    "    states, actions,rewards, next_states, dones = replay_buffer.sample() #returns torch tensors\n",
    "\n",
    "    # POLICY ITERATION STEP\n",
    "    #Update the Q-function parameters\n",
    "\n",
    "    next_actions, next_log_pis = policy.sample(next_states)\n",
    "\n",
    "    next_qf1 = target_qf1.forward(next_states,next_actions)\n",
    "    next_qf2 = target_qf2.forward(next_states,next_actions)\n",
    "\n",
    "    if single_q:\n",
    "        next_q_target = next_qf1 - alpha * next_log_pis\n",
    "    else:\n",
    "        next_q_target = torch.min(next_qf1,next_qf2) - alpha * next_log_pis\n",
    "\n",
    "    expected_q = rewards + (1 - dones) * discount * next_q_target\n",
    "\n",
    "    curr_qf1 = qf1.forward(states,actions)\n",
    "    curr_qf2 = qf2.forward(states,actions)\n",
    "\n",
    "    qf1_loss = F.mse_loss(curr_qf1, expected_q.detach())\n",
    "    qf2_loss = F.mse_loss(curr_qf2, expected_q.detach())\n",
    "\n",
    "    qf1_optimizer.zero_grad()\n",
    "    qf1_loss.backward()\n",
    "    qf1_optimizer.step()\n",
    "\n",
    "    qf2_optimizer.zero_grad()\n",
    "    qf2_loss.backward()\n",
    "    qf2_optimizer.step()\n",
    "\n",
    "    # POLICY IMPROVEMENT STEP\n",
    "    new_actions,log_pi = policy.sample(states)\n",
    "    if update_step % delay_step ==0:\n",
    "        min_q = torch.min(qf1.forward(states, new_actions),\n",
    "                          qf2.forward(states, new_actions))\n",
    "        #alpha = log_alpha.exp()\n",
    "        policy_loss = (alpha * log_pi - min_q).mean()\n",
    "        \n",
    "        #Update policy weights\n",
    "        policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        policy_optimizer.step()\n",
    "\n",
    "        #Update target network weights at every iteration\n",
    "\n",
    "        for target_params, params in zip(target_qf1.parameters(), qf1.parameters()):\n",
    "            target_params.data.copy_(soft_target_tau * params + (1 - soft_target_tau) * target_params)\n",
    "\n",
    "        for target_params, params in zip(target_qf2.parameters(), qf2.parameters()):\n",
    "            target_params.data.copy_(soft_target_tau * params + (1 - soft_target_tau) * target_params)\n",
    "    \n",
    "    #Adjust entropy temperature\n",
    "    if auto_entropy_tuning:    \n",
    "        log_alpha_optim.zero_grad()\n",
    "        alpha_loss = (log_alpha * (-log_pi - target_entropy).detach()).mean()\n",
    "        alpha_loss.backward()\n",
    "        log_alpha_optim.step()\n",
    "        alpha = log_alpha.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 100\tLast Score: -19.17; average score: 4.48; alpha: 0.0209"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aafcd8ff24b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meach_iteration\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0mepisods_before_learning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# and (each_environment_step % update_every == 0):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mupdate_step\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-67a3cfa8381d>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#Update policy weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mpolicy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mpolicy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mpolicy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/drlnd/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if train_mode:\n",
    "\n",
    "    #TRAINING ALGORITHM\n",
    "    \n",
    "    scores = []                        # list containing scores from each episode\n",
    "    #scores = np.zeros(num_agents)\n",
    "    \n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "\n",
    "    for each_iteration in range(num_epochs):\n",
    "\n",
    "        #score = np.zeros(num_agents)\n",
    "        score = 0\n",
    "        update_step = 0\n",
    "\n",
    "        env_info=env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "        state = env_info.vector_observations[0]\n",
    "        #state = env_info.vector_observations\n",
    "        \n",
    "        for each_environment_step in range(num_steps_per_epoch):\n",
    "\n",
    "            #sample action from the policy\n",
    "            action = policy.get_action(state)            \n",
    "\n",
    "            new_action = np.asarray([0] * 220)\n",
    "            action2 = np.concatenate((action,new_action))\n",
    "            env_info = env.step(action2)[brain_name]\n",
    "\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            #next_state = env_info.vector_observations\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            score += reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "\n",
    "            #Store the transition in the replay pool\n",
    "            replay_buffer.add(state, action, reward, next_state, done)\n",
    "\n",
    "            if (replay_buffer.buffer_len() > batch_size) and (each_iteration +1 >episods_before_learning): # and (each_environment_step % update_every == 0):            \n",
    "                update_step+=1\n",
    "                update()\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            if done or each_environment_step == num_steps_per_epoch - 1:\n",
    "                break\n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save all the scores\n",
    "        \n",
    "        if each_iteration % 10 ==0:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if auto_entropy_tuning:\n",
    "                print('\\rEpisode {}\\tLast Score: {:.2f}; average score: {:.2f}; alpha: {:.4f}'.format(each_iteration, score,np.mean(scores_window),alpha.detach().item()), end=\"\")\n",
    "            else:\n",
    "                print('\\rEpisode {}\\tLast Score: {:.2f}; average score: {:.2f}; alpha: {:.4f}'.format(each_iteration, score,np.mean(scores_window),alpha), end=\"\")\n",
    "                \n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "            plt.plot(np.arange(++len(scores)), scores)\n",
    "            plt.ylabel('Score')\n",
    "            plt.xlabel('Episode #')\n",
    "            plt.show()\n",
    "\n",
    "        if score > solve_score and first_30==0:\n",
    "            first_30 = each_iteration\n",
    "\n",
    "        if np.mean(scores_window)>=solve_score:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(each_iteration-100, np.mean(scores_window)))\n",
    "            break         \n",
    "\n",
    "    env.close()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode and save_mode:\n",
    "    torch.save(qf1.state_dict(), 'checkpoint_qf1.pth')\n",
    "    torch.save(qf2.state_dict(), 'checkpoint_qf2.pth')\n",
    "    torch.save(policy.state_dict(), 'checkpoint_policy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE DATA INTO CSV FILE FOR FURTHER ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_mode:\n",
    "    import csv\n",
    "    from datetime import datetime\n",
    "\n",
    "    now = datetime.now() \n",
    "    experience_name = \"SAC FV\"\n",
    "    date_time = str(now.strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "\n",
    "    all_scores = np.asarray(scores)\n",
    "\n",
    "    solved_ep = each_iteration - 100\n",
    "    first_above_30 = first_30\n",
    "\n",
    "    total_points = all_scores.sum()\n",
    "    variance = np.var(all_scores)\n",
    "    scores_per_episod = all_scores.mean()\n",
    "\n",
    "    with open('crawler_results.csv', mode='a') as results_file:\n",
    "        results_writer = csv.writer(results_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        results_writer.writerow([experience_name, date_time, solved_ep, first_30, scores_per_episod, variance, all_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch the Crawler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not train_mode:\n",
    "\n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    t_step=0\n",
    "    rewards_history=[]\n",
    "    nb_episodes = 10\n",
    "    \n",
    "    for episodes in range (nb_episodes):\n",
    "\n",
    "        scores = np.zeros(num_agents) # initialize the score (for each agent) \n",
    "        t_step=0\n",
    "        while True:\n",
    "            actions = policy.get_action2(states)                # select an action (for each agent)\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            t_step+=1\n",
    "            rewards_history.append(rewards)\n",
    "            if np.all(dones) or t_step>2000:                   # exit loop if episode finished\n",
    "                break\n",
    "        print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))\n",
    "    print ('Total score: {}'.format(np.sum(rewards_history)))\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Total score: {}'.format(np.sum(rewards_history)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
